{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quick Machine Learning Modelling Tutorial with Python and Scikit-Learn (sklearn)\n",
    "\n",
    "\n",
    "## TODO - What is Scikit-Learn (sklearn)?\n",
    "\n",
    "[NumPy](https://docs.scipy.org/doc/numpy/index.html) stands for numerical Python. It's the backbone of all kinds of scientific and numerical computing in Python.\n",
    "\n",
    "And since machine learning is all about turning data into numbers and then figuring out the patterns, NumPy often comes into play.\n",
    "\n",
    "<img src=\"images/6-step-ml-framework-tools-numpy-highlight.png\" alt=\"a 6 step machine learning framework along will tools you can use for each step\" width=\"700\"/>\n",
    "\n",
    "## TODO - Why Scikit-Learn?\n",
    "\n",
    "You can do numerical calculations using pure Python. In the beginning, you might think Python is fast but once your data gets large, you'll start to notice slow downs.\n",
    "\n",
    "One of the main reasons you use NumPy is because it's fast. Behind the scenes, the code has been optimized to run using C. Which is another programming language, which can do things much faster than Python.\n",
    "\n",
    "The benefit of this being behind the scenes is you don't need to know any C to take advantage of it. You can write your numerical computations in Python using NumPy and get the added speed benefits.\n",
    "\n",
    "If your curious as to what causes this speed benefit, it's a process called vectorization. [Vectorization](https://en.wikipedia.org/wiki/Vectorization) aims to do calculations by avoiding loops as loops can create potential bottlenecks.\n",
    "\n",
    "NumPy achieves vectorization through a process called [broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#module-numpy.doc.broadcasting).\n",
    "\n",
    "\n",
    "## TODO - What does this notebook cover?\n",
    "\n",
    "The NumPy library is very capable. However, learning everything off by heart isn't necessary. Instead, this notebook focuses on the main concepts of NumPy and the `ndarray` datatype.\n",
    "\n",
    "You can think of the `ndarray` datatype as a very flexible array of numbers.\n",
    "\n",
    "More specifically, we'll look at:\n",
    "* NumPy datatypes & attributes\n",
    "* Creating arrays\n",
    "* Viewing arrays & matrices (indexing)\n",
    "* Manipulating & comparing arrays\n",
    "* Sorting arrays\n",
    "* Use cases (examples of turning things into numbers)\n",
    "\n",
    "After going through it, you'll have the base knolwedge of NumPy you need to keep moving forward.\n",
    "\n",
    "## TODO - Where can I get help?\n",
    "If you get stuck or think of something you'd like to do which this notebook doesn't cover, don't fear!\n",
    "\n",
    "The recommended steps you take are:\n",
    "1. **Try it** - Since NumPy is very friendly, your first step should be to use what you know and try figure out the answer to your own question (getting it wrong is part of the process). If in doubt, run your code.\n",
    "2. **Search for it** - If trying it on your own doesn't work, since someone else has probably tried to do something similar, try searching for your problem. You'll likely end up in 1 of 2 places:\n",
    "    * [NumPy documentation](https://docs.scipy.org/doc/numpy/index.html) - the ground truth for everything NumPy, this resource covers all of the NumPy functionality.\n",
    "    * [Stack Overflow](https://stackoverflow.com/) - this is the developers Q&A hub, it's full of questions and answers of different problems across a wide range of software development topics and chances are, there's one related to your problem.\n",
    "    \n",
    "An example of searching for a NumPy function might be:\n",
    "\n",
    "> \"how to find unique elements in a numpy array\"\n",
    "\n",
    "Searching this on Google leads to the NumPy documentation for the `np.uniquie()` function: https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html\n",
    "\n",
    "The next steps here are to read through the documentation, check the examples and see if they line up to the problem you're trying to solve. If they do, **rewrite the code** to suit your needs, run it, and see what the outcomes are.\n",
    "\n",
    "3. **Ask for help** - If you've been through the above 2 steps and you're still stuck, you might want to ask your question on [Stack Overflow](https://www.stackoverflow.com). Be as specific as possible and provide details on what you've tried.\n",
    "\n",
    "Remember, you don't have to learn all of the functions off by heart to begin with. \n",
    "\n",
    "What's most important is continually asking yourself, \"what am I trying to do with the data?\".\n",
    "\n",
    "Start by answering that question and then practicing finding the code which does it.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics to cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Focus on a few topics which a student can use to get started\n",
    "* Concepts should be covered which are covered in the heart disease project\n",
    "* An Scikit-Learn/sklearn workflow is paramount, start with that and work backwards \n",
    "\n",
    "Concepts to go over before the code:\n",
    "* Getting data ready (splitting into train and test sets)\n",
    "* Choosing the algorithm (called estimator, model... etc)\n",
    "* Choosing the hyperparameters (knobs you can turn on your model)\n",
    "* Fitting the model to the data (easy to do if your data is ready)\n",
    "* Evaluating the model (different problems have different metrics)\n",
    "* Use the model to make predictions on the future (unseen data)\n",
    "* Experimentation\n",
    "    * Trying different models\n",
    "    * Trying different hyperparameters\n",
    "    * Getting more data\n",
    "\n",
    "* Things to watch out for:\n",
    "    * High-bias models: underfits the data\n",
    "    * High-variance models: overfits the data\n",
    "    * A model will never, except by chance, give a better score to the validation set than the training set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow\n",
    "\n",
    "Show a student what it looks like going through the heart disease dataset and building a machine learning model to classify whether a patient has heart disease and then use the model to predict whether a new patient has heart disease or not (could use my own data for this).\n",
    "\n",
    "Take the heart disease dataset, split it, fit a model, check out the model, introduce these with the steps:\n",
    "\n",
    "1. Get data ready (`train_test_split()`, `X`, `y`)\n",
    "2. Choose a model (Scikit-Learn estimator cheatsheet - https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) \n",
    "3. Choose the hyperparameters (different for each model)\n",
    "4. Fit the model\n",
    "5. Evaluate the model\n",
    "6. Use the model to make a prediction\n",
    "    * Step 5 & 6 are similar because to evaluate the model we'll be making predictions with it \n",
    "7. Experiment to improve \n",
    "8. Save model for use elsewhere\n",
    "\n",
    "Once students have seen an end-to-end workflow, work backwards through each step.\n",
    "\n",
    "Put all of these steps into a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Workflow for Classifying Heart Disease\n",
    "\n",
    "#### 1. Get the data ready\n",
    "\n",
    "We'll import the `heart-disease.csv` file we've been working with to create a scikit-learn workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "heart_disease = pd.read_csv('../data/heart-disease.csv')\n",
    "\n",
    "# Create X (all the feature columns)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (the target column)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: target, dtype: int64, 1    165\n",
       " 0    138\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(), y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 13), (76, 13), (227,), (76,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Choose the model\n",
    "This is often referred to as `model` or `clf` (short for classifier) or estimator (as in the Scikit-Learn) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Choose the hyperparameters\n",
    "Hyperparameters are like knobs on an oven you can tune to cook your favourite dish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll leave as default to begin with...\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit the model to the data\n",
    "Fitting the model on the data involves passing it the data and asking it to figure out the patterns. \n",
    "\n",
    "If there are labels (supervised learning), the model tries to work out the relationship between the data and the labels. \n",
    "\n",
    "If there are no labels (unsupervised learning), the model tries to find patterns and group similar samples together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate the model\n",
    "\n",
    "Each model or estimator has a built-in score method. This method compares how well the model was able to learn the patterns between the features and labels. In other words, it returns how accurate your model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9779735682819384"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157894736842105"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Use the model to make a prediction\n",
    "\n",
    "The whole point of training a machine learning model is to use it to make some kind of prediction in the future.\n",
    "\n",
    "Once our model instance is trained, you can use the `predict()` method to predict a target value given a set of features. In other words, use the model, along with some unlabelled data to predict the label. \n",
    "\n",
    "Note, data you predict on has to be in the same shape as data you trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-5dda9944c71f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This doesn't work... incorrect shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# This doesn't work... incorrect shapes\n",
    "y_label = model.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "137   62    1   1       128   208    1        0      140      0      0.0   \n",
       "69    62    0   0       124   209    0        1      163      0      0.0   \n",
       "12    49    1   1       130   266    0        1      171      0      0.6   \n",
       "51    66    1   0       120   302    0        0      151      0      0.4   \n",
       "293   67    1   2       152   212    0        0      150      0      0.8   \n",
       "\n",
       "     slope  ca  thal  \n",
       "137      2   0     2  \n",
       "69       2   0     2  \n",
       "12       2   0     2  \n",
       "51       1   0     2  \n",
       "293      1   0     3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to predict a label, data has to be in the same shape as X_train\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make a prediction on the test data (further evaluation)\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've made some predictions, we can start to use some more scikit-learn methods to figure out how good our model is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        32\n",
      "           1       0.86      0.82      0.84        44\n",
      "\n",
      "    accuracy                           0.82        76\n",
      "   macro avg       0.81      0.82      0.81        76\n",
      "weighted avg       0.82      0.82      0.82        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26,  6],\n",
       "       [ 8, 36]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157894736842105"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Experiment to improve\n",
    "\n",
    "The first model you build is often referred to as a baseline.\n",
    "\n",
    "Once you've got a baseline model, like we have here, it's important to remember, this is often not the final model you'll use.\n",
    "\n",
    "The next step in the workflow is to try and improve upon your baseline model.\n",
    "\n",
    "And to do this, there's two ways to look at it. From a model perspective and from a data perspective.\n",
    "\n",
    "From a model perspective this may involve things such as using a more complex model or tuning your models hyperparameters.\n",
    "\n",
    "From a data perspective, this may involve collecting more data or better quality data so your existing model has more of a chance to learn the patterns within.\n",
    "\n",
    "If you're already working on an existing dataset, it's often easier try a series of model perspective experiments first and then turn to data perspective experiments if you aren't getting the results you're looking for.\n",
    "\n",
    "One thing you should be aware of is if you're tuning a models hyperparameters in a series of experiments, your reuslts should always be cross-validated. Cross-validation is a way of making sure the results you're getting are consistent across your training and test datasets (because it uses multiple versions of training and test sets) rather than just luck because of the order the original training and test sets were created. \n",
    "\n",
    "* Try different hyperparameters\n",
    "* All different parameters should be cross-validated \n",
    "    * **Note:** Beware of cross-validation for time series problems \n",
    "    \n",
    "Different models you use will have different hyperparameters you can tune. For the case of our model, the `RandomForestClassifier()`, we'll start trying different values for `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 78.94736842105263%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 82.89473684210526%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 78.94736842105263%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 81.57894736842105%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 81.57894736842105%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 81.57894736842105%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 84.21052631578947%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 78.94736842105263%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 81.57894736842105%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try different numbers of estimators (trees)... (no cross-validation)\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {model.score(X_test, y_test) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 78.94736842105263%\n",
      "Cross-validation score: 78.53551912568305%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 80.26315789473685%\n",
      "Cross-validation score: 79.84699453551912%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 82.89473684210526%\n",
      "Cross-validation score: 80.50819672131148%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 85.52631578947368%\n",
      "Cross-validation score: 82.15300546448088%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 80.26315789473685%\n",
      "Cross-validation score: 81.1639344262295%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 78.94736842105263%\n",
      "Cross-validation score: 83.47540983606557%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 82.89473684210526%\n",
      "Cross-validation score: 81.83060109289617%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 81.57894736842105%\n",
      "Cross-validation score: 82.81420765027322%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 82.89473684210526%\n",
      "Cross-validation score: 82.81967213114754%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# With cross-validation\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {model.score(X_test, y_test) * 100}%\")\n",
    "    print(f\"Cross-validation score: {np.mean(cross_val_score(model, X, y, cv=5)) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 80}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to do it with GridSearchCV...\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameters to search over\n",
    "param_grid = {'n_estimators': [i for i in range(10, 100, 10)]}\n",
    "\n",
    "# Setup the grid search\n",
    "grid = GridSearchCV(RandomForestClassifier(),\n",
    "                    param_grid,\n",
    "                    cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Find the best parameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to be the best estimator\n",
    "model = grid.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best model\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026315789473685"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model scores\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Save a model for someone else to use\n",
    "\n",
    "When you've done a few experiments and you're happy with how your model is doing, you'll likely want someone else to be able to use it.\n",
    "\n",
    "This may come in the form of a teammate or colleague trying to replicate and validate your results or through a customer using your model as part of a service or application you offer.\n",
    "\n",
    "Saving a model also allows you to reuse it later without having to go through retraining it. Which is helpful, especially when your training times start to increase.\n",
    "\n",
    "You can save a scikit-learn model using Python's in-built `pickle` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(model, open(\"random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631578947368421"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a saved model and make a prediction\n",
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the data ready\n",
    "\n",
    "* Splitting data into X and y (features and targets)\n",
    "* `train_test_split()`\n",
    "* Splitting time series data (beware of validation sets)\n",
    "\n",
    "Two things to remember:\n",
    "    * Making sure it's all numerical\n",
    "        * How to encode something? (`one_hot...`)\n",
    "        * Turn car_sales into a larger dataset with missing and categorical values\n",
    "    * Making sure there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into X & y\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "..     ...  ..   ...  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop('target', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, Length: 303, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2) # you can change the test size\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% of data is being used for the test set \n",
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure it's all numerical\n",
    "* One-hot encoding categories (or another method of encoding) - https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "\n",
    "We want to turn the `\"Make\"` and `\"Colour\"` columns into numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820</td>\n",
       "      <td>4</td>\n",
       "      <td>32042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>155144</td>\n",
       "      <td>3</td>\n",
       "      <td>5716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604</td>\n",
       "      <td>4</td>\n",
       "      <td>31570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883</td>\n",
       "      <td>4</td>\n",
       "      <td>4001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360</td>\n",
       "      <td>4</td>\n",
       "      <td>12732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors  Price\n",
       "0     Honda  White          35431      4  15323\n",
       "1       BMW   Blue         192714      5  19943\n",
       "2     Honda  White          84714      4  28343\n",
       "3    Toyota  White         154365      4  13434\n",
       "4    Nissan   Blue         181577      3  14043\n",
       "..      ...    ...            ...    ...    ...\n",
       "995  Toyota  Black          35820      4  32042\n",
       "996  Nissan  White         155144      3   5716\n",
       "997  Nissan   Blue          66604      4  31570\n",
       "998   Honda  White         215883      4   4001\n",
       "999  Toyota   Blue         248360      4  12732\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import car-sales-extended.csv\n",
    "car_sales = pd.read_csv(\"../data/car-sales-extended.csv\")\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y and train/test\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and build a model on our `car_sales` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Honda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ecb56ad8f06d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Honda'"
     ]
    }
   ],
   "source": [
    "# Try to predict with random forest on price column (doesn't work)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops... this doesn't work, we'll have to convert it to numbers first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 3.5431e+04])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             Honda\n",
       "Colour           White\n",
       "Odometer (KM)    35431\n",
       "Doors                4\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way... using pandas and pd.get_dummies()\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "      <th>Doors_3</th>\n",
       "      <th>Doors_4</th>\n",
       "      <th>Doors_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0           0           1            0            0             0   \n",
       "1           1           0            0            0             0   \n",
       "2           0           1            0            0             0   \n",
       "3           0           0            0            1             0   \n",
       "4           0           0            1            0             0   \n",
       "..        ...         ...          ...          ...           ...   \n",
       "995         0           0            0            1             1   \n",
       "996         0           0            1            0             0   \n",
       "997         0           0            1            0             0   \n",
       "998         0           1            0            0             0   \n",
       "999         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  Doors_3  Doors_4  \\\n",
       "0              0             0           0             1        0        1   \n",
       "1              1             0           0             0        0        0   \n",
       "2              0             0           0             1        0        1   \n",
       "3              0             0           0             1        0        1   \n",
       "4              1             0           0             0        1        0   \n",
       "..           ...           ...         ...           ...      ...      ...   \n",
       "995            0             0           0             0        0        1   \n",
       "996            0             0           0             1        1        0   \n",
       "997            1             0           0             0        0        1   \n",
       "998            0             0           0             1        0        1   \n",
       "999            1             0           0             0        0        1   \n",
       "\n",
       "     Doors_5  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "995        0  \n",
       "996        0  \n",
       "997        0  \n",
       "998        0  \n",
       "999        0  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to convert doors to object for dummies to work on it...\n",
    "car_sales[\"Doors\"] = car_sales[\"Doors\"].astype(object)\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Toyota    398\n",
       "Honda     304\n",
       "Nissan    198\n",
       "BMW       100\n",
       "Name: Make, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The categorical categories are now either 1 or 0...\n",
    "X[\"Make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28838980751757537"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if there were missing values?\n",
    "\n",
    "* Make sure there are no missing values\n",
    "* Filling the variables up with the mean (there are other ways to do this and it's a hard challenge, filling data where there isn't any?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import car sales dataframe with missing values\n",
    "car_sales_missing = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-2a49b486c91e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                  categorical_features)],\n\u001b[1;32m     11\u001b[0m                                  remainder=\"passthrough\")\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtransformed_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_sales_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtransformed_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m    419\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0;32m--> 420\u001b[0;31m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 self._categorical_features, copy=True)\n\u001b[1;32m    630\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_legacy_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mX_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_categories\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mXi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[0;32m---> 67\u001b[0;31m                              force_all_finite=needs_validation)\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "# Let's convert the categorical columns to one hot encoded (code copied from above)\n",
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh... this doesn't work. We'll have to either fill or remove the missing values.\n",
    "\n",
    "Let's see what values are missing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'll do is fill the rows where categorical values are missing with `\"missing\"`, the numerical features with the mean or 4 for the doors. And drop the rows where the Price is missing. \n",
    "\n",
    "We could fill Price with the mean, however, since it's the target variable, we don't want to be introducing too many fake labels.\n",
    "\n",
    "**Note:** The practice of filling missing data is called **imputation**. And it's important to remember there's no perfect way to fill missing data. The methods we're using are only one of many. The techniques you use will depend heavily on your dataset. A good place to look would be searching for \"data imputation techniques\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our dataframe\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Price labels\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've removed the rows with missing Price values, now there's less data but there's no more missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's one-hot encode the categorical columns (copied from above)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 3.5431e+04,\n",
       "       1.5323e+04])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing data with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've filled the missing columns using pandas functions, you might be thinking, \"Why pandas? I thought this was a Scikit-Learn introduction?\".\n",
    "\n",
    "Not to worry, scikit-learn provides another method called [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) which allows us to do a similar thing.\n",
    "\n",
    "`SimpleImputer()` transforms data by filling missing values with a given strategy.\n",
    "\n",
    "And we can use it to fill the missing values in our DataFrame as above.\n",
    "\n",
    "At the moment, our dataframe has no mising values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reimport it so it has missing values and we can fill them with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reimport the DataFrame\n",
    "car_sales_missing = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing in the \"Price\" column\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill categorical values with 'missing' & numerical with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different column features\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "numerical_feature = [\"Odometer (KM)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Honda', 'White', 4.0, 35431.0],\n",
       "       ['BMW', 'Blue', 5.0, 192714.0],\n",
       "       ['Honda', 'White', 4.0, 84714.0],\n",
       "       ...,\n",
       "       ['Nissan', 'Blue', 4.0, 66604.0],\n",
       "       ['Honda', 'White', 4.0, 215883.0],\n",
       "       ['Toyota', 'Blue', 4.0, 248360.0]], dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, categorical_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, numerical_feature)])\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our transformed array back into a DataFrame\n",
    "car_sales_filled = pd.DataFrame(filled_X, \n",
    "                                columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see the original... still missing values\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<950x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's one hot encode the features with the same code as before \n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17283858824953835"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we've transformed X, let's see if we can fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this looks confusing, don't worry, we've covered a lot of ground very quickly. And we'll revisit these strategies in a future section in way which makes a lot more sense.\n",
    "\n",
    "For now, the key takeaways to remember are:\n",
    "* Most datasets you come across won't be in a form ready to immediately start using them with machine learning models. And some may take more preparation than others to get ready to use.\n",
    "* For most machine learning models, your data has to be numerical. This will involve converting whatever you're working with into numbers. This process is often referred to as **feature engineering** or **feature encoding**.\n",
    "* Some machine learning models aren't compatible with missing data. The process of filling missing data is referred to as **data imputation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Choosing the right estimator/algorithm for your problem\n",
    "\n",
    "Once you've got your data ready, the next step is to choose an appropriate machine learning algorithm or model to find patterns in your data.\n",
    "\n",
    "Some things to note:\n",
    "* Sklearn refers to machine learning models and algorithms as estimators.\n",
    "* Classification problem - predicting a category (heart disease or not).\n",
    "    * Sometimes you'll see `clf` (short for classifier) used as a classification instance's variable name.\n",
    "* Regression problem - predicting a number (selling price of a car).\n",
    "* Unsupervised problem - clustering (grouping unlabelled samples with other similar unlabelled samples).\n",
    "\n",
    "If you know what kind of problem you're working with, one of the next places you should look at is the Scikit-Learn algorithm cheatsheet.\n",
    "\n",
    "This cheatsheet gives you a bit of an insight into the algorithm you might want to use for the problem you're working on.\n",
    "\n",
    "It's important to remember, you don't have to explicitly know what each algorithm is doing on the inside to start using them. If you do start to apply different algorithms but they don't seem to be working, that's when you'd start to look deeper into each one.\n",
    "\n",
    "Let's check out the cheatsheet and follow it for some of the problems we're working on.\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map.png\" />\n",
    "\n",
    "You can see it's split into four main categories. Regression, classification, clustering and dimensionality reduction. Each has their own different purpose but the Scikit-Learn team has designed the library so the workflows for each are relatively similar.\n",
    "\n",
    "Let's start with a regression problem. We'll use the Boston housing dataset built into Scikit-Learn's `datasets` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Boston housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston # imports as dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's in a dictionary, let's turn it into a DataFrame so we can inspect it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = pd.DataFrame(boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "boston_df[\"target\"] = pd.Series(boston[\"target\"])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples?\n",
    "len(boston_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, our goal here is to use the feature columns, such as `CRIM`, which is the per capita crime rate by town, `AGE`, the proportion of owner-occupied units built prior to 1940 and more to predict the `target` column. Where the `target` column is the median house prices.\n",
    "\n",
    "In essence, each row is a different town (data) in Boston and we're trying to build a model to predict the median house price (label) of a town given a series of attributes about the town.\n",
    "\n",
    "Since we have data and labels, this is a supervised learning problem. And since we're trying to predict a number, it's a regression problem.\n",
    "\n",
    "Knowing these two things, how do they line up on the Scikit-Learn machine learning algorithm cheat-sheet?\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-boston-housing-ridge.png\" />\n",
    "\n",
    "Following the map through, knowing what we know, it suggests we try [`RidgeRegression`](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression). Let's chek it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168522"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Ridge model class from the linear_model module\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if `RidgeRegression` didn't work?\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-boston-housing-ensemble.png\" />\n",
    "\n",
    "Following the diagram, the next step would be to try [`EnsembleRegressors`](https://scikit-learn.org/stable/modules/ensemble.html). Ensemble is another word for multiple models put together to make a decision.\n",
    "\n",
    "One of the most common and useful ensemble methods is the [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest). Known for its fast training and prediction times and adaptibility to different problems.\n",
    "\n",
    "The basic premise of the Random Forest is to combine a number of different decision trees, each one random from the other and make a prediction on a sample by averaging the result of each decision tree.\n",
    "\n",
    "An in-depth discussion of the Random Forest algorithm is beyond the scope of this notebook but if you're interested in learning more, [An Implementation and Explanation of the Random Forest in Python](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) by Will Koehrsen is a great read.\n",
    "\n",
    "Since we're working with regression, we'll use Scikit-Learn's [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "We can use the exact same workflow as above. Except for changing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8477414419760558"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, we get a boost in score on the test set of almost 0.2 with a change of model.\n",
    "\n",
    "At first, the diagram can seem confusing. But once you get a little practice applying different models to different problems, you'll start to pick up which sorts of algorithms do better with different types of data.\n",
    "\n",
    "### Picking an algorithm for a classification problem\n",
    "Now, let's check out the choosing process for a classification problem.\n",
    "\n",
    "Say you were trying to predict whether or not a patient had heart disease based on their medical records.\n",
    "\n",
    "The dataset in `../data/heart-disease.csv` contains data for just that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples are there?\n",
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Boston housing dataset, here we want to use all of the available data to predict the target column (1 for if a patient has heart disease and 0 for if they don't).\n",
    "\n",
    "So what do we know?\n",
    "\n",
    "We've got 303 samples (1 row = 1 sample) and we're trying to predict whether or not a patient has heart disease.\n",
    "\n",
    "Because we're trying to predict whether each sample is one thing or another, we've got a classification problem.\n",
    "\n",
    "Let's see how it lines up with our [Scikit-Learn algorithm cheat-sheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-heart-disease-linear-svc.png\"/>\n",
    "\n",
    "Following the cheat-sheet we end up at [`LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) which stands for Linear Support Vector Classifier. Let's try it on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47540983606557374"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import LinearSVC from the svm module\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "model = LinearSVC(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight out of the box (with no tuning or improvements) the model scores 47% accuracy, which with 2 classes (heart disease or not) is as good as guessing.\n",
    "\n",
    "With this result, we'll go back to our diagram and see what our options are.\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-heart-disease-ensemble.png\"/>\n",
    "\n",
    "Following the path (and skipping a few, don't worry, we'll get to this) we come up to [`EnsembleMethods`](https://scikit-learn.org/stable/modules/ensemble.html) again. Except this time, we'll be looking at ensemble classifiers instead of regressors.\n",
    "\n",
    "Remember our [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) from above? We'll it has a dance partner, [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) which is an ensemble based machine model learning model for classification. You might be able to guess what we can use it for.\n",
    "\n",
    "Let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `RandomForestClassifier` we get almost double the score of `LinearSVC`.\n",
    "\n",
    "One thing to remember, is both models are yet to receive any hyperparameter tuning. Hyperparameter tuning is fancy term for adjusting some settings on a model to try and make it better. It usually happens once you've found a decent baseline result you'd like to improve upon.\n",
    "\n",
    "In this case, we'd probably take the `RandomForestClassifier` and try and improve it with hyperparameter tuning (which we'll see later on).\n",
    "\n",
    "### What about the other models?\n",
    "\n",
    "Looking at the cheat-sheet and the examples above, you may have noticed we've skipped a few.\n",
    "\n",
    "Why?\n",
    "\n",
    "The first reason is time. Covering every single one would take a fair bit longer than what we've done here. And the second one is the effectiveness of ensemble methods.\n",
    "\n",
    "A little tidbit for modelling in machine learning is:\n",
    "* If you have structured data (tables or dataframes), use ensemble methods, such as, a Random Forest.\n",
    "* If you have unstructured data (text, images, audio, things not in tables), use deep learning or transfer learning.\n",
    "\n",
    "For this notebook, we're focused on structured data, which is why the Random Forest has been our model of choice.\n",
    "\n",
    "If you'd like to learn more about the Random Forest and why it's the war horse of machine learning, check out these resources:\n",
    "* [Random Forest Wikipedia](https://en.wikipedia.org/wiki/Random_forest)\n",
    "* [Random Forests in Python](http://blog.yhat.com/posts/random-forests-in-python.html) by yhat\n",
    "* [An Implementation and Explanation of the Random Forest in Python](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) by Will Koehrsen\n",
    "\n",
    "### Experiment until something works\n",
    "\n",
    "The beautiful thing is, the way the Scikit-Learn API is designed, once you know the way with one model, using another is much the same.\n",
    "\n",
    "And since a big part of being a machine learning engineer or data scientist is experimenting, you might want to try out some of the other models on the cheat-sheet and see how you go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit the model to data\n",
    "\n",
    "Now you've chosen a model, the next step is to have it learn from the data so it can be used for predictions in the future.\n",
    "\n",
    "If you've followed through, you've seen a few examples of this already.\n",
    "\n",
    "In Scikit-Learn, the process of having a machine learning model learn things from a dataset involves calling the `fit()` method and passing it data, such as, `fit(X, y)`.\n",
    "\n",
    "Where `X` is a feature array and `y` is a target array.\n",
    "\n",
    "Other names for `X` include:\n",
    "* Data\n",
    "* Feature variables\n",
    "* Features\n",
    "\n",
    "Other names for `y` include:\n",
    "* Labels\n",
    "* Target variable\n",
    "\n",
    "For supervised learning there is usually an `X` and `y`. For unsupervised learning, there's no `y`.\n",
    "\n",
    "Let's revisit the example of using patient data (`X`) to predict whether or not they have heart disease (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "Calling the `fit()` method will cause the machine learning algorithm to attempt to find patterns between `X` and `y`. Or if there's no `y`, it'll be only within `X`.\n",
    "\n",
    "Let's see `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `X` and `y` to to the model will cause it to go through all of the examples in `X` (data) and see what their corresponding `y` (label) is.\n",
    "\n",
    "How the model does this is different depending on the model you use.\n",
    "\n",
    "Explaining the details of each would take an entire textbook. \n",
    "\n",
    "For now, you could imagine it similar to how you would figure out patterns if you had enough time. \n",
    "\n",
    "You'd look at the feature variables, `X`, the `age`, `sex`, `chol` (cholesterol) and see what different values led to the labels, `y`, `1` for heart disease, `0` for not heart disease.\n",
    "\n",
    "This concept, regardless of the problem, is similar throughout all of machine learning.\n",
    "\n",
    "**During training:**\n",
    "\n",
    "A machine learning algorithm looks at a dataset, finds patterns, tries to use those patterns to predict something and corrects itself as best it can with the available data and labels. It stores these patterns for later use.\n",
    "\n",
    "**During testing (or in production):**\n",
    "\n",
    "A machine learning algorithm uses the patterns its previously learned in a dataset to make a prediction on some unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - 5. Evaluate the model\n",
    "\n",
    "Once you've trained a model, you'll want a way to measure how trustworthy its predictions are.\n",
    "\n",
    "Scikit-Learn implements 3 different methods of evaluating models.\n",
    "\n",
    "1. The `score()` method. Calling `score()` on a model instance will return a metric assosciated with the type of model you're using. The metric depends on which model you're using.\n",
    "2. The `scoring` parameter. This parameter can be passed to methods such as [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) or `GridSearchCV()` to tell Scikit-Learn to use a specific type of scoring metric.\n",
    "3. Problem-specific metric functions. Similar to how the `scoring` parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "The scoring function you use will also depend on the problem you're working on.\n",
    "\n",
    "Classification problems have different evaluation metrics and scoring functions to regression problems.\n",
    "\n",
    "Let's look at some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. General model evaluation with `score()`\n",
    "\n",
    "If we bring down the code from our previous classification problem. To predict whether or not someone has heart disease based on their medical records.\n",
    "\n",
    "We can see the `score()` method come into play.\n",
    "\n",
    "**Note:** For this example, `model` has been changed to `clf`, short for classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been fit on the training data (`X_train`, `y_train`), we can call the `score()` method on it and evaluate our model on the test data, data the model has never seen before (`X_test`, `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `clf` is an instance of `RandomForestClassifier`, the `score()` method uses mean accuracy as its score method.\n",
    "\n",
    "You can find this by pressing **SHIFT + TAB** within the brackets of `score()` when called on a model instance.\n",
    "\n",
    "Behind the scenes, `score()` makes predictions on `X_test` using the trained model and then compares those predictions to the actual labels `y_test`.\n",
    "\n",
    "A model which predicts everything 100% correct would receive a score of 1.0 (or 100%).\n",
    "\n",
    "Our model doesn't get everything correct, but at 85% (0.85 * 100), it's still far better than guessing.\n",
    "\n",
    "Let's do the same but with the regression code from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the consistent design of the Scikit-Learn library, we can call the same `score()` method on `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8477414419760558"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `model` is an instance of `RandomForestRegressor`. And since it's a regression model, the default metric built into `score()` is the coefficient of determination or R^2 (pronounced R-sqaured).\n",
    "\n",
    "Remeber, you can find this by pressing **SHIFT + TAB** within the brackets of `score()` when called on a model instance.\n",
    "\n",
    "The best possible value here is 1.0, this means the model predicts the target regression values exactly.\n",
    "\n",
    "Calling the `score()` method on any model instance and passing it test data is a good quick way to see how your model is going.\n",
    "\n",
    "However, when you get further into a problem, it's likely you'll want to start using more powerful metrics to evaluate your models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluating your models using the `scoring` parameter \n",
    "\n",
    "The next step up from using `score()` is to use a custom `scoring` parameter with `cross_val_score()` or `GridSearchCV`.\n",
    "\n",
    "As you may have guessed, the `scoring` parameter you set will be different depending on the problem you're working on.\n",
    "\n",
    "We'll see some specific examples of different parameters in a moment but first let's check out `cross_val_score()`.\n",
    "\n",
    "To do so, we'll copy the heart disease classification code from above and then add another line at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import cross_val_score from the model_selection module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `cross_val_score()` is slightly different to `score()`. Let's see a code example first and then we'll go through the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using score()\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/ml-course/zero-to-mastery-ml/env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82178218, 0.81188119, 0.8019802 ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score()\n",
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "The first difference you might notice is `cross_val_score()` returns an array where as `score()` only returns a single number.\n",
    "\n",
    "`cross_val_score()` returns an array because of a parameter called `cv`, which stands for cross-validation.\n",
    "\n",
    "When `cv` isn't set, `cross_val_score()` will return an array of 3 numbers by default (or 5 by default if you're using Scikit-Learn version 0.22).\n",
    "\n",
    "Remember, you can see the parameters of a function using **SHIFT + TAB** from within the brackets.\n",
    "\n",
    "But wait, you might be thinking, what even is cross-validation?\n",
    "\n",
    "A visual might be able to help.\n",
    "\n",
    "<img src='../images/sklearn-cross-validation.png'/>\n",
    "\n",
    "We've dealt with Figure 1.0 before using `score(X_test, y_test)`. But looking deeper into this, if a model is trained using the training data or 80% of samples, this means 20% of samples aren't used for the model to learn anything.\n",
    "\n",
    "This also means depending on what 80% is used to train on and what 20% is used to evaluate the model, it may achieve a score which doesn't reflect the entire dataset. For example, if a lot of easy examples are in the 80% training data, when it comes to test on the 20%, your model may perform poorly. The same goes for the reverse.\n",
    "\n",
    "Figure 2.0 shows 5-fold cross-validation, a method which tries to provide a solution to:\n",
    "\n",
    "1. Not training on all the data\n",
    "2. Avoiding getting lucky scores on single splits of the data\n",
    "\n",
    "Instead of training only on 1 training split and evaluating on 1 testing split, 5-fold cross-validation does it 5 times. On a different split each time, returning a score for each.\n",
    "\n",
    "Why 5-fold?\n",
    "\n",
    "A better name would've been K-fold. Where K is an abitrary number. 5 just looks nice visually.\n",
    "\n",
    "Figure 2.0 is what happens when we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75409836, 0.83606557, 0.81967213, 0.75      , 0.78333333])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-fold cross-validation\n",
    "cross_val_score(clf, X, y, cv=5) # cv is equivalent to K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we set `cv=5` (5-fold cross-validation), we get back 5 different scores instead of 1.\n",
    "\n",
    "Taking the mean of this array be give us a more in-depth idea of how our model is performing by converting the 5 scores into one.\n",
    "\n",
    "Notice, the average `cross_val_score()` is slightly lower than single value returned by `score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8150819672131148)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "# Take mean of 5-fold cross-validation\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if you were asked to report the accuracy of your model, even though it's lower, you'd prefer the cross-validated metric over the non-cross-validated metric.\n",
    "\n",
    "Wait?\n",
    "\n",
    "We haven't used the `scoring` parameter at all.\n",
    "\n",
    "By default, it's set to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80327869, 0.81967213, 0.85245902, 0.76666667, 0.75      ])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=5, scoring=None) # default scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `scoring` is set to `None` (by default), it uses the same metric as `score()` for whatever model is passed to `cross_val_score()`.\n",
    "\n",
    "In this case, our model is `clf` which is an instance of `RandomForestClassifier` which uses mean accuracy as the default `score()` metric.\n",
    "\n",
    "You can change the evaluation score `cross_val_score()` uses by changing the `scoring` parameter.\n",
    "\n",
    "And as you might have guessed, different problems call for different evaluation scores.\n",
    "\n",
    "The [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) outlines a vast range of evaluation metrics for different problems but let's have a look at a few.\n",
    "\n",
    "# NEXT:\n",
    "* Go through classification metrics (accuracy, log loss, area under ROC curve, confusion matrix, classification report, precision, recall, f1 score)\n",
    "* Go through regression metrics (mse, mae, R^2)\n",
    "* Complete method 3. \"calling methods directly\" e.g. mean_accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - Classification model evaluation metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Log loss\n",
    "3. Area under ROC curve\n",
    "4. Confusion matrix\n",
    "5. Classification report\n",
    "    * precision - ability of a classifier to label a sample as positive which is actually negaitve \n",
    "        * For example, for a text search on a set of documents, precision is the number of correct results divided by the number of all returned results.\n",
    "    * recall - ability of a model to find all positive samples, also called true positive rate or sensitivity\n",
    "        * For example, for a text search on a set of documents, recall is the number of correct results divided by the number of results that should have been returned.\n",
    "    * f1-score\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - Regression model evaluation metrics\n",
    "1. Mean absolute error (MAE)\n",
    "2. Mean squared error (MSE)\n",
    "3. R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix with 2 options\n",
    "1. Seaborn with `sns.heatmap()`\n",
    "2. Scikit-Learns `plot_confusion_matrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a16c79290>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Plot a confusion matrix with Seaborn\n",
    "import seaborn as sns\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Install a package within the current Jupyter Kernel\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: Matplotlib is currently broken, hence why this plot seems weird, will wait for an update or see what's wrong in the video\n",
    "\n",
    "See this StackOverflow for reference: https://stackoverflow.com/questions/56942670/matplotlib-seaborn-first-and-last-row-cut-in-half-of-heatmap-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.set(font_scale=1.4)\n",
    "ax = sns.heatmap(conf_mat,\n",
    "            square=False,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot a confusion matrix using the function in scikit-learn's documentation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a confusion matrix with sklearn\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "# Call the function\n",
    "plot_confusion_matrix(y_test, \n",
    "                      y_preds, \n",
    "                      classes=heart_disease[\"target\"].unique());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to maximise the above error, but minimise the two values below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036.7105"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8065.222273114982"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean absolute error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean     16045.665000\n",
       "std       8630.794219\n",
       "min       2796.000000\n",
       "25%       9481.500000\n",
       "50%      14264.000000\n",
       "75%      20738.750000\n",
       "max      52458.000000\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales[\"Price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use the model to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Explore more options (experimentation)\n",
    "* Turn hypyerparameters manually, with `GridSearchCV` and `RandomSearchCV`\n",
    "    * You should use cross-validation here\n",
    "    * Train on the training set, tune on validation set, test on test set\n",
    "    * You might've seen throughout a warning appear when we call the RandomForest models, if not, you're using a later \n",
    "* Ways to improve your model\n",
    "    * Data perspective\n",
    "        * Feature importance\n",
    "    * Model perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - Run this code... warning appears, \"number of estimators is changing\", number of estimators is something we can alter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Call the fit function on the model and pass it training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Saving and exporting a model\n",
    "* Use `pickle` to save, export and reload a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Revisit the pipeline one more time, knowing what we know now\n",
    "* Go through an end to end example, filling values, encoding data (one hot), imputing data and putting it all in pipelines with `Pipeline()`.\n",
    "* This should finsih with an end-to-end workflow in one cell which can be described in a diagram/flowchart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an sklearn pipeline which imports data, fixes it and models it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
